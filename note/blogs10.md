# Lecture 10 NLP II

## In-class Material

1. [Slides](../slides/w10.pdf)

2. [Notebook](../code/week10.zip)

### Extra Reading

1. [2019 Offering: Notebook for Some NLP Tools](../code/week8/week8.zip)

2. [Transfer Learning in NLP](https://docs.google.com/presentation/d/1LsUAhR_qIVbq6xH6Aw4ag8MGB_-UWfd0KoVhtTgye6o/edit?usp=sharing)

3. [RNN vs Autoregressive Models: Transformer](https://bair.berkeley.edu/blog/2018/08/06/recurrent/)

4. [Awesome BERT & Transfer Learning in NLP ](https://github.com/cedrickchee/awesome-bert-nlp)

5. [Why BERT Fails In Commercial Environments](https://www.intel.ai/bert-commercial-environments/)

6. [RNN Tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)

7. [When Recurrent Models Don't Need to be Recurrent](https://bair.berkeley.edu/blog/2018/08/06/recurrent/)

8. [The Time Series Transformer](https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3)